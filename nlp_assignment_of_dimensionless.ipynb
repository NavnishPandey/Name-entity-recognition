{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install SpeechRecognition"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pp0RgXvVh6Ob",
        "outputId": "3ffa39ce-8c81-4912-8f09-aa27fda62001"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting SpeechRecognition\n",
            "  Downloading SpeechRecognition-3.10.0-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
            "Installing collected packages: SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mhw4qNachr6r",
        "outputId": "9a91d8a3-f93a-4187-d5c4-648681d62ba0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcription: hello hi Nancy this is Mike from AT&T Incorporation\n"
          ]
        }
      ],
      "source": [
        "import speech_recognition as sr\n",
        "\n",
        "audio_file = \"/content/sales_call_telephone_marketers.wav\"\n",
        "\n",
        "r = sr.Recognizer()\n",
        "\n",
        "with sr.AudioFile(audio_file) as source:\n",
        "    audio = r.record(source)\n",
        "\n",
        "try:\n",
        "    transcription = r.recognize_google(audio)  \n",
        "    print(\"Transcription: \" + transcription)\n",
        "except sr.UnknownValueError:\n",
        "    print(\"Speech recognition could not understand audio\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import unicode_literals, print_function\n",
        "#import plac\n",
        "import random\n",
        "from pathlib import Path\n",
        "import spacy\n",
        "from tqdm import tqdm "
      ],
      "metadata": {
        "id": "4PowgvdG_WUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_DATA = [('what is the price of polo?', {'entities': [(21, 25, 'PrdName')]}), ('what is the price of ball?', {'entities': [(21, 25, 'PrdName')]}), \n",
        " ('what is the price of jegging?', {'entities': [(21, 28, 'PrdName')]}), ('what is the price of t-shirt?', {'entities': [(21, 28, 'PrdName')]}), \n",
        "  ('what is the price of jeans?', {'entities': [(21, 26, 'PrdName')]}), ('what is the price of bat?', {'entities': [(21, 24, 'PrdName')]}),\n",
        "   ('what is the price of shirt?', {'entities': [(21, 26, 'PrdName')]}), ('what is the price of bag?', {'entities': [(21, 24, 'PrdName')]}),\n",
        "    ('what is the price of cup?', {'entities': [(21, 24, 'PrdName')]}), ('what is the price of jug?', {'entities': [(21, 24, 'PrdName')]}),\n",
        "     ('what is the price of plate?', {'entities': [(21, 26, 'PrdName')]}), ('what is the price of glass?', {'entities': [(21, 26, 'PrdName')]}), \n",
        "      ('what is the price of moniter?', {'entities': [(21, 28, 'PrdName')]}), ('what is the price of desktop?', {'entities': [(21, 28, 'PrdName')]}), \n",
        "       ('what is the price of bottle?', {'entities': [(21, 27, 'PrdName')]}), ('what is the price of mouse?', {'entities': [(21, 26, 'PrdName')]}),\n",
        "        ('what is the price of keyboad?', {'entities': [(21, 28, 'PrdName')]}), ('what is the price of chair?', {'entities': [(21, 26, 'PrdName')]}), \n",
        "         ('what is the price of table?', {'entities': [(21, 26, 'PrdName')]}), ('what is the price of watch?', {'entities': [(21, 26, 'PrdName')]})]\n",
        "    "
      ],
      "metadata": {
        "id": "mUovMtNuszcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = None\n",
        "output_dir=Path(\"/content/output\")\n",
        "n_iter=100\n",
        "\n",
        "if model is not None:\n",
        "    nlp = spacy.load(model)  \n",
        "    print(\"Loaded model '%s'\" % model)\n",
        "else:\n",
        "    nlp = spacy.blank('en')  \n",
        "    print(\"Created blank 'en' model\")"
      ],
      "metadata": {
        "id": "TF8YIf2R_EmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if 'ner' not in nlp.pipe_names:\n",
        "    ner = nlp.create_pipe('ner')\n",
        "    nlp.add_pipe(ner, last=True)\n",
        "else:\n",
        "    ner = nlp.get_pipe('ner')\n",
        "\n",
        "\n",
        "for _, annotations in TRAIN_DATA:\n",
        "    for ent in annotations.get('entities'):\n",
        "        ner.add_label(ent[2])\n",
        "\n",
        "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
        "with nlp.disable_pipes(*other_pipes):  \n",
        "    optimizer = nlp.begin_training()\n",
        "    for itn in range(n_iter):\n",
        "        random.shuffle(TRAIN_DATA)\n",
        "        losses = {}\n",
        "        for text, annotations in tqdm(TRAIN_DATA):\n",
        "            nlp.update(\n",
        "                [text],  \n",
        "                [annotations],  \n",
        "                drop=0.5,  \n",
        "                sgd=optimizer,\n",
        "                losses=losses)\n",
        "        print(losses)"
      ],
      "metadata": {
        "id": "MA-8sTsM_iZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for text, _ in TRAIN_DATA:\n",
        "    doc = nlp(text)\n",
        "    print('Entities', [(ent.text, ent.label_) for ent in doc.ents])\n",
        "    print('Tokens', [(t.text, t.ent_type_, t.ent_iob) for t in doc])"
      ],
      "metadata": {
        "id": "qG1u1EJ8_ibi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if output_dir is not None:\n",
        "    output_dir = Path(output_dir)\n",
        "    if not output_dir.exists():\n",
        "        output_dir.mkdir()\n",
        "    nlp.to_disk(output_dir)\n",
        "    print(\"Saved model to\", output_dir) "
      ],
      "metadata": {
        "id": "F098Noei_ied"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp2 = spacy.load(output_dir)\n",
        "for text, _ in TRAIN_DATA:\n",
        "    doc = nlp2(text)\n",
        "    print('Entities', [(ent.text, ent.label_) for ent in doc.ents])\n",
        "    print('Tokens', [(t.text, t.ent_type_, t.ent_iob) for t in doc])"
      ],
      "metadata": {
        "id": "chPy-VJn_ig7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp2 = spacy.load(output_dir)\n",
        "doc = nlp2(transcription)\n",
        "print('Entities', [(ent.text, ent.label_) for ent in doc.ents])\n",
        "print('Tokens', [(t.text, t.ent_type_, t.ent_iob) for t in doc])"
      ],
      "metadata": {
        "id": "OsaJndQ__ijW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MVM3a6-0_im4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}